---
title: "Spacecraft GNC 6: A Simple Attitude Determination System"
date: 2024-09-20
excerpt: "A practical example of online attitude estimation from sun sensor and magnetometer data."
---

# Overview

This is a bit of a milestone. In this post we're going to make use of what we've learned in just about every preceding post since this blog began. We're going to use all of this knowledge to build a functional attitude determination system (ADS) and test it in simulation.

We'll tackle this in three steps. First off - a review of the prerequisite material, with links to the corresponding posts. Next, a detailed walkthrough of the ADS and simulation code. Finally, a discussion of what's still missing, that is: things that aren't yet modeled in the simulation and ways in which the ADS itself can be improved.

Let's get started.

# Review

Roughly speaking, our ADS is an Extended Kalman Filter that uses Coarse Sun Sensor (CSS) and Three-Axis Magnetometer (TAM) data, as well as a model of spacecraft attitude dynamics, to provide a statistical estimate of attitude and angular velocity at each time step.

## ADS

First let's remember *why* we need to estimate attitude. Many of the things that spacecraft do (navigate, take photos, conduct science experiments) require precise knowledge of the orientation of the spacecraft. That is, its attitude. Because life is hard, there's no single "attitude sensor" that can sense attitude by inspecting the fabric of the universe, so we must collect what data is available to us and use clever algorithms to estimate attitude using this data. The spacecraft subsystem that does this is the ADS. Importantly, we need to orient ourselves with respect to at least 2 different reference vectors in order to estimate our full attitude.

Post: https://alexmcmaster.github.io/blog/2024/07/19/ad.html

## Basilisk

Getting hardware into space is expensive, so in order to develop our ADS we use a simulation framework called Basilisk. Basilisk allows us to define our spacecraft, set some initial conditions, and see how the spacecraft moves over time. It also allows us to generate sensor readings that reflect the simulated environment. Sensor data collected from this simulation is then used as the input to our ADS, and the output estimates of our ADS are compared with the simulated spacecraft states in order to assess estimator performance.

Post: https://alexmcmaster.github.io/blog/2024/07/12/bsk.html

## The CSS

One sensor that is part of almost every ADS is the CSS: basically just a photocell that outputs a current proportional to the intensity of the light that hits its collection surface. From the magnitude of the output current we can infer the angle at which the sensor pointing direction is off from the direction of the Sun (this is a simplification, see the "What's Missing" section for more info). By putting several of these sensors on our spacecraft, all pointing in different directions, we can ensure that at least one is always pointed near enough the Sun to produce some output current, and so we can effectively measure our orientation with respect to the Sun vector.

Post: https://alexmcmaster.github.io/blog/2024/07/26/css.html

## The TAM

Another common sensor is the TAM, which measures the local magnetic field in the X, Y, and Z directions. That is, it measures the (3d) local magnetic field vector. This sensor is paired with a magnetic field model that, given our location, can tell us what the local magnetic field should be in the inertial frame. By comparing this vector with our measured vector we can effectively measure our orientation with respect to the local magnetic field.

Post: https://alexmcmaster.github.io/blog/2024/08/09/mag.html

## Kalman Filtering

I made a reference above to the "clever algorithms" that we use to turn sensor data into attitude estimates. Well, when I said this I was referring to the Kalman Filter and its derivatives. The Kalman Filter is a way of using sensor measurements in an optimal way so as to produce the best possible estimates from a statistical perspective (subject to certain constraints). That's all I will say here. If you're not already familiar with the Kalman Filter, I strongly recommend that you read the post linked below.

Post: https://alexmcmaster.github.io/blog/2024/05/31/kf.html

## The EKF

The Kalman Filter requires that the mapping from current state to subsequent state (the process model) as well as the mapping from current state to corresponding sensor values (the measurement model) are linear. Unfortunately, attitude estimation is inherently *non*linear. One way of resolving this issue is to linearize the nonlinear models at each time step. When you add this element to a Kalman Filter it becomes an EKF. More info in the EKF post.

Post: https://alexmcmaster.github.io/blog/2024/06/07/ekf.html

# Code

I used the term "online attitude estimation" in the title of this post, which isn't quite accurate. While the ADS described in this section is perfectly capable of running online, doing so is difficult because it requires integration into Basilisk. Not only does this require a deal of upfront work, but it would make debugging the ADS considerably harder, since bugs could arise not only in the ADS but also in the integration between the ADS and Basilisk. Further, all of the Basilisk Flight Software (FSW) algorithms are implemented in C, which, though it is a great language for speedy flight software algorithms, is an abysmal language for educational content like this. Anyway, our simulation and evaluation process will take place in 4 steps.

1) Run the simulation to generate sensor/state data.

2) Prepare the data.

3) Run the ADS on the data.

4) Analyze the results.

We will review the code for each of these steps in turn.

## 1) Run the Simulation

You can find the full simulation script [here](https://github.com/alexmcmaster/basilisk/blob/develop/sims/sim4-ads.py).

This script defines a simulated environment (with an Earth, Sun, and Moon) and a spacecraft (with an inertia tensor, 6 CSSs, a TAM), sets some initial conditions (time, s/c position and velocity), and simulates several minutes of the ensuing dynamics. After the simulation completes, certain time series data are saved to a set of files. These data include:  

1) The absolute time at each time step.

2) The true s/c attitude using Modified Rodrigues Parameters (MRPs)*.

3) The accumulated number of MRP switches*.

4) The true s/c angular rates.

5) The true s/c position vector.

6) The CSS measurements.

7) The true Sun vector in the inertial frame.

8) The TAM measurements.

9) The true local magnetic field vector in the inertial frame.

10) The IMU readings (these are not used).

\* MRPs are one of the many available attitude parameterizations. Though certainly not the most common one, they do have some nice properties, one of which is that they encode attitude in only 3 parameters without any singularities, provided that a suitable switching strategy is applied. MRPs are used extensively in Basilisk. However, you do not need to understand them to follow this post because we convert from MRPs to unit quaternions for our ADS, as you will see in the "Prepare the Data" section. More information on MRPs [here](https://ntrs.nasa.gov/api/citations/19960035754/downloads/19960035754.pdf).

## 2) Prepare the Data

First we load the raw data generated by the simulation script.

```python
# Load state data from sim.
time_s = np.load("data/time_s.npy")                     # Simulation time (s).
sigma_bn_mrp = np.load("data/sigma_bn_mrp.npy")         # Attitude MRP in inertial frame.
mrp_switches = np.load("data/mrp_switches.npy")         # Accumulated MRP switches.
omega_bn_b = np.load("data/omega_bn_b.npy")             # Angular velocity of the spacecraft (rad/s).
r_bn_n = np.load("data/r_bn_n.npy")                     # Position of the s/c relative to Earth (m).
css_meas = np.load("data/css.npy")                      # Coarse Sun Sensor (CSS) data.
sun_vectors_inertial = np.load("data/sun.npy")          # Position of the Sun relative to Earth (m).
tam_meas = np.load("data/tam.npy")                      # Three-axis Magnetometer (TAM) data.
mag_fields_earth_fixed = np.load("data/mag_field.npy")  # Local magnetic field (T).
```

Next we convert the true attitude from MRPs to unit quaternions (also known as Euler Parameters, or "EPs"). While it's possible, and in some ways advantageous, to use MRPs in an ADS, EPs are much more common in practice, so for educational content I think they make more sense.

```python
def mrp2ep(m):
    m_mag = np.dot(m, m.T)
    return np.array([(1 - m_mag) / (1 + m_mag)] + [(2 * m_i) / (1 + m_mag) for m_i in m])

# Convert attitude data from MRP to EP (accounting for MRP switching).
q_bn = np.apply_along_axis(mrp2ep, axis=1, arr=sigma_bn_mrp)
q_bn[np.where(mrp_switches % 2)[0]] = q_bn[np.where(mrp_switches % 2)[0]] * -1
```

Remember that when we use a TAM for attitude estimation we are comparing the _direction_ of the measured local magnetic field with the _direction_ of the modeled local magnetic field. What we are explicitly *not* using is the *magnitude* of the field. In fact, preserving the magnitude will just confuse our filter because the CSS data is already normalized to [0, 1]. So we need to normalize the magnetic field vectors (measured and modeled) as well.

```python
# Normalize mag field model and measurements (CSS already normalized).
normalize = lambda v: v / np.linalg.norm(v)
tam_meas = np.apply_along_axis(normalize, axis=1, arr=tam_meas)
mag_fields_earth_fixed = np.apply_along_axis(normalize, axis=1, arr=mag_fields_earth_fixed)
```

Our EKF needs the inertia matrix of the spacecraft and the orientations of its CSSs, as will be shown in the next section.

```python
# Orientations of the coarse sun sensors.
css_vectors = np.array((
    ( 1,  0,  0), (-1,  0,  0),  # +/- X
    ( 0,  1,  0), ( 0, -1,  0),  # +/- Y
    ( 0,  0,  1), ( 0,  0, -1),  # +/- Z
))

# Spacecraft moment of inertia.
moi = np.array((
    (900., 0., 0.),  # X
    (0., 800., 0.),  # Y
    (0., 0., 600.),  # Z
))
```

Finally, it is convenient to combine our data into (1) a time series of ground truth state vectors containing true EP attitude and angular rates and (2) a time series of CSS and TAM measurements.

```python
# Stack attitude and angular rates to form ground truth 7d state history.
state_gt = np.hstack((q_bn, omega_bn_b))

# Stack CSS and TAM measurements to form 9d measurements history.
meas = np.hstack((css_meas, tam_meas))
```

## 3) Run the ADS on the Data

As with any Kalman Filter, we must first define our initial state and covariance estimates, the process noise covariance, and the measurement noise covariance. The initial state and covariance are set wide to capture the fact that we have no initial knowledge, save that the angular rates probably aren't too high (maximum angular rates are typically provided in the documentation of the deployment hardware). The process noise is set pretty low. We are sort of cheating here, because, in fact, there *is no process noise*. Our filter uses the same process model as the simulation itself, and we don't subject the s/c to any disturbances during the simulation, so we essentially have a perfect process model. This limitation will be discussed more in the "What's Missing" section below. Finally, the measurement noise covariance is set to reflect the noise parameters given to the sensors in the simulation script.

```python
# Initial state and covariance estimates.
x_init = np.array((0.5, 0.5, 0.5, 0.5, 0.1, 0.1, 0.1))
P_init = np.diag((0.5, 0.5, 0.5, 0.5, 0.1, 0.1, 0.1))

# Process noise covariance.
Q = np.diag(
    4 * [1e-4]  # Quaternion variance.
  + 3 * [1e-4]  # Angular velocity variance.
)

# Measurement noise covariance.
R = np.diag(
    6 * [1e-4]  # CSS noise variance.
  + 3 * [1e-7]  # TAM noise variance.
)
```

Next we pass this stuff in along with the sensor and model data captured from the simulation and let the ADS generate estimates for every time step.

```python
# Instantiate the ADS.
ads = AttitudeEstimatorEKF(css_orientations=css_vectors, sc_moment_of_inertia=moi)

# Evaluate the ADS.
estimates, estimates_cov, residuals, measurements_est = ads.evaluate(
    t=time_s, x_init=x_init, P_init=P_init, Q=Q, R=R,
    controls=controls, measurements=meas,
    sc_positions_inertial=r_bn_n,
    sun_vectors_inertial=sun_vectors_inertial,
    mag_fields_earth_fixed=mag_fields_earth_fixed,
)
```

That last excerpt was absurdly high level, so let's dig deeper. The ```evaluate``` method generates estimates at each time step within the simulation and returns the resulting time series. The most important outputs are the ```estimates``` and ```estimates_cov```, which represent the state estimates and the corresponding covariances, respectively. The ```residuals``` are not strictly required, but can be helpful for troubleshooting, particularly if there is an issue with the measurement model or its Jacobian.

```python
def evaluate(self, t, x_init, P_init, Q, R, controls, measurements,
             sc_positions_inertial, sun_vectors_inertial, mag_fields_earth_fixed):
    """Produce iterative estimates across a given time range."""
    
    # Set up containers to store estimates.
    estimates = np.zeros((len(t), len(x_init)))
    estimates_cov = np.zeros((len(t), len(x_init)))
    estimates[0] = x_init
    estimates_cov[0] = np.diag(P_init)
    
    # Handy for troubleshooting and analysis.
    residuals = np.zeros((len(t), measurements.shape[1]))
    
    # Initialize state and covariance.
    x, P = x_init, P_init
    
    # Simulate each time step and store the results.
    for k in tqdm(range(1, len(t))):
        
        dt = t[k] - t[k-1]
        u = controls[k]
        z = measurements[k]
        sc_position_inertial = sc_positions_inertial[k]
        sun_vector_inertial = sun_vectors_inertial[k]
        mag_field_earth_fixed = mag_fields_earth_fixed[k]
        
        x, P, y = self.estimate(dt, x, P, u, z,
                                sc_position_inertial,
                                sun_vector_inertial,
                                mag_field_earth_fixed)
        
        estimates[k] = x
        estimates_cov[k] = np.diag(P)
        residuals[k] = y
    
    return estimates, estimates_cov, residuals
```

Let's go one level deeper and look at the ```estimate``` method.

```python
def estimate(self, dt, x, P, u, z, sc_position_inertial, sun_vector_inertial, mag_field_earth_fixed):
    """Estimate current state from previous state and current measurements."""
    x, P = self._prediction_step(dt, x, P, u)
    x, P, y = self._correction_step(dt, x, P, z, sc_position_inertial, sun_vector_inertial, mag_field_earth_fixed)
    return x, P, y
```

Ok, not too much to see here. Let's go down another level and look at how the prediction and correction steps work.

```python
def _prediction_step(self, dt, x, P, u):
    # Linearize process model about x[k-1].
    F = self.numerical_jacobian(
        functools.partial(self._process_model, dt=dt, u=None), 7, 7, x
    )
    
    # Advance state using full, nonlinear process model.
    x = self._process_model(x, dt, u)
    x[:4] /= np.linalg.norm(x[:4])
    
    # Advance state covariance using linearized process model F.
    P = F @ P @ F.T + Q
    
    return x, P

def _correction_step(self, dt, x, P, z, sc_position_inertial, sun_vector_inertial, mag_field_earth_fixed):
    # Linearize measurement model about predicted x.
    H = self.numerical_jacobian(
        functools.partial(self._measurement_model, sc_position_inertial=sc_position_inertial,
                                                   sun_vector_inertial=sun_vector_inertial,
                                                   mag_field_earth_fixed=mag_field_earth_fixed),
        9, 7, x
    )
    
    # Calculate measurement residual using full, nonlinear measurement model.
    h = self._measurement_model(x, sc_position_inertial, sun_vector_inertial, mag_field_earth_fixed)
    y = z - h
    
    # Use Jacobian for all further calculations.
    S = H @ P @ H.T + R
    K = P @ H.T @ np.linalg.inv(S)
    x = x + K @ y
    x[:4] /= np.linalg.norm(x[:4])
    P = (np.eye(len(P)) - K @ H) @ P
    return x, P, y
```

I'm not going to spend too much time on these methods, since they're mostly the same for every EKF. One thing that's worth noting is that they use numerical differentiation to get the process and measurement model Jacobians. While this is fairly inefficient at runtime, and should generally be avoided in a polished implementation, it's convenient for development purposes because it makes it less of a pain to change the process and measurement models. A full-featured ADS on a modern remote sensing satellite might have a couple dozen state variables and measurement variables, which means that calculating the Jacobians will require solving hundreds of partial derivatives by hand. If a model changes, the partial derivatives need to be redone. So, best to save this particular optimization until the process and measurement models are etched in stone.

Now we're going to go one more level down and take a look at the heart of our EKF: the process and measurement models themselves.

The process model can be broken into two pieces: the attitude (quaternion) dynamics and the angular velocity dynamics. The attitude dynamics tell us how the attitude will change over a duration ```dt``` given the starting attitude ```q``` and angular velocities ```w```. While it's certainly possible to derive this yourself, I have not. I learned this equation [here](https://www.coursera.org/learn/spacecraft-dynamics-kinematics). Note that we have to re-normalize the resulting quaternion, otherwise it's not a valid attitude and our filter will probably become unstable. The angular velocity dynamics tell us how the angular velocities will change over ```dt``` given the starting velocities ```w``` and the spacecraft's inertia matrix ```self.sc_moi```. This implementation is based on [Euler's Rotation Equations](https://en.wikipedia.org/wiki/Euler%27s_equations_(rigid_body_dynamics)) with the additional assumption of no external torques.

One thing to note: we are quantizing a process that, in the real world, is continuous, which is a source of error. It's important that ```dt``` be kept small to minimize this error. (If right now you're thinking "well _actually_, the real world is not continuous", your homework is to determine how much better this system would be if it accounted for quantum effects. Go on. Do it. I would actually love to read that paper.)

```python
@staticmethod
def _W_matrix(w):
    wx, wy, wz = w
    return np.array((
        (0,  -wx, -wy, -wz),
        (wx,  0,   wz, -wy),
        (wy, -wz,  0,   wx),
        (wz,  wy, -wx,  0 )
    ))

def _process_model(self, x, dt, u):
    q, w = x[:4], x[4:]
    x_hat = np.zeros(7)

    # Quaternion dynamics.
    q_dot = 0.5 * self._W_matrix(w) @ q
    x_hat[:4] = q + q_dot * dt
    x_hat[:4] /= np.linalg.norm(x_hat[:4])

    # Angular velocity dynamics.
    w_dot = np.linalg.inv(self.sc_moi) @ (np.cross(-w, self.sc_moi @ w))
    x_hat[4:] = w + w_dot * dt

    return x_hat
```

Ok, finally onto the measurement model. The measurement model takes the current best state estimate and outputs what it expects the sensor measurements to be. The difference between the output of the measurement model and the measurements themselves is called the measurement residual (see the Kalman Filter post for more information about this very important quantity). Our measurement model comes in two parts: the CSS model and the TAM model. For the CSS model we must first calculate the Sun vector in the body frame and the distance from the spacecraft to the Sun. Next we use the orientations of the 6 CSS units to predict the output of each one using a series of steps outlined in the Basilisk CSS documentation (see PDF link in comment). For the TAM model all we have to do is transform the magnetic field vector from our magnetic field model into the body frame, which we do by converting our attitude quaternion into a rotation matrix (DCM) and multiplying.

```python
def _measurement_model(self, x, sc_position_inertial, sun_vector_inertial, mag_field_earth_fixed):
    q, w = x[:4], x[4:]
    
    h = np.zeros(9)
    
    body_dcm_est = quat2dcm(q)

    # CSS measurement model.        
    sun_vector_relative = sun_vector_inertial - sc_position_inertial
    sun_vector_body = (body_dcm_est @ sun_vector_relative) / np.linalg.norm(sun_vector_relative)
    sun_distance = np.linalg.norm(sun_vector_inertial)
    for i in range(6):
        # See https://hanspeterschaub.info/basilisk/_downloads/5a5aa3cb20faf38a4d8da52afc25a9b6/Basilisk-CoarseSunSensor-20170803.pdf
        gamma_hat = np.dot(self.css_ors[i], sun_vector_body)
        gamma_k = gamma_hat  # NOTE: assuming kelly factor of 0
        gamma_li = gamma_k * (AU2m(1) ** 2) / (sun_distance ** 2)  # NOTE: assuming no eclipse
        gamma_clean = gamma_li  # NOTE: assuming scaling factor is 1
        h[i] = np.max((0, gamma_clean))
    
    # TAM measurement model.
    mag_field_body = body_dcm_est @ mag_field_earth_fixed
    h[6:] = mag_field_body
    
    return h
```

And that's how our ADS works! Now let's see how *well* it works.

## 4) Analyze the Results

```python
# Plot results.
ads.plot(t=time_s, ground_truth=state_gt, estimates=estimates, estimates_cov=estimates_cov,
         measurements=meas, residuals=residuals)
```

<img src="{{ site.baseurl }}/assets/ads/sim1.png" width="100%" />

What do we see here? Well it's clearly working. Convergence happens within a few seconds and errors remain low throughout the simulation. Normally you would not expect convergence to happen this quickly, but this is still a pretty idealized simulation: there are a lot of additional complications that we're not simulating, the most significant of which will be covered in the "What's Missing" section below.

Let's zoom in on the first few seconds.

```python
# Take a closer look at convergence behavior.
ads.plot(t=time_s, ground_truth=state_gt, estimates=estimates, estimates_cov=estimates_cov,
         measurements=meas, residuals=residuals, end_idx=100)
```

<img src="{{ site.baseurl }}/assets/ads/sim2.png" width="100%" />

Attitude converges within about 200 ms, and angular rate estimates take a few seconds. Similar story for the measurement residuals (as one should expect).

Now let's zoom in on the steady-state behavior.

```python
# Look at steady-state behavior.
ads.plot(t=time_s, ground_truth=state_gt, estimates=estimates, estimates_cov=estimates_cov,
         measurements=meas, residuals=residuals, start_idx=100)
```

<img src="{{ site.baseurl }}/assets/ads/sim3.png" width="100%" />

Steady-state error is on the order of 1 degree for attitude and maybe 0.2 degrees/second for rates. This is too high for something like an imaging satellite, but is pretty good for an ADS that relies solely on CSS and TAM, which are not the most accurate of sensors.

While the steady-state error is *pretty* consistent, there is some fluctuation. Let's see if we can figure out where that's coming from.

Here's what the CSS outputs look like.

<img src="{{ site.baseurl }}/assets/ads/css.png" width="100%" />

Most of the time the Sun is within the field of view of 3 out of our 6 CSSs, but briefly at around 20, 45, 90, 125, 165, and 205 seconds it is only within view of 2 (instantaneously, actually, because our CSSs have 180 degree fields of view). It is following these instants that the attitude error temporarily increases. This is because at these times we are getting less information from our sensors. If a CSS reports a value of, say, 0.5, we know that even if there's some noise, the true value is pretty close to 0.5. This measurement carries a lot of information - it constrains the set of possible Sun vectors to the surface of a cone. If, however, the CSS reports a value of 0, then that CSS could be pointing anywhere that's not within 90 degrees of the Sun, which means the set of possible Sun vectors is an entire hemisphere.

You might say "well, if 4 of the CSS units output 0, then we should know the Sun vector exactly just based on which two units have nonzero values". This is true in theory; the problem is noise. When a CSS is oriented close enough to 90 degrees off the Sun vector, sensor noise will cause it to sometimes report 0. In this way it is possible to have 4 or even 5 CSSs reporting zero, which causes uncertainty to increase. Why does this increased uncertainty persist for several seconds? Because the covariance estimate ```P``` depends on its previous value, and so it takes time for this added uncertainty to filter out, even after we are back to 3 nonzero CSS measurements. So, in other words, these transient errors are fundamental to our design.

# What's Missing

What has been presented above is a good start, but it is too simplistic to result in a successful space mission. So, let's talk about possible improvements. We'll consider two categories: (1) ways in which the simulation can be improved for increased realism and (2) ways in which the ADS can be improved for increased performance.

## Ways to Improve the Simulation

While our simulation captures the core dynamics of a satellite in LEO, it ignores many of the smaller effects that would be experienced by a real spacecraft on orbit. These are mostly negligible on small time scales, that is, in the vicinity of our ```dt```, however, some of them can be quite significant on longer time scales, such as across an entire orbit. We can improve our simulation's realism, and thus its utility, by modeling these effects. Here are some of the most important such effects:

* **Albedo**. Our CSS measurement model makes the woefully inaccurate assumption that the Sun is the only source of light in the solar system. In fact, the Earth, which in LEO will take up nearly half of our field of view, reflects somewhere between 30 and 40% of incident sunlight. This reflection is known as Earth's *albedo*. We can model this in our simulation to improve realism, and can account for it in our CSS measurement model to ensure that it doesn't confuse our ADS. (Note: the Moon has a much smaller albedo, but can still affect ADS accuracy if unaccounted for.)
* **Solar Radiation Pressure (SRP)**. Though massless, sunlight has momentum and can (will) transfer that momentum to our spacecraft. The magnitude of this momentum transfer depends on how reflective or absorptive the surface of our spacecraft is (see [here](https://en.wikipedia.org/wiki/Elastic_collision) to understand why). This leads to one obvious and one subtle effect. The obvious one is an external force pointing away from the Sun. The subtle one is an external *torque*, whose magnitude depends upon the degree of symmetry of the face of the spacecraft facing the Sun, with respect to reflectivity (i.e. if one side of the face is highly reflective and the other is highly absorbtive, the magnitude of the torque will be high). This can be accounted for in the process model.
* **Atmospheric Drag**. LEO is in "space" by any reasonable definition. However, especially in lower regions, there can still be enough atmosphere to have a non-negligible impact on spacecraft dynamics. Similar to SRP, drag imparts an obvious external force and a less-obvious external torque, subject to the offset between the centers of aerodynamic pressure and mass orthogonal to the direction of motion. This can be accounted for in the process model.
* **Magnetic Moment**. Virtually every spacecraft is an electric device and, therefore, will have some sort of a residual magnetic moment. What happens when you have two magnetic moments in close proximity? They will tend to align, which means that if they're not already aligned, torques are imparted so as to align them (this is how a compass works). In other words, an orbiting satellite will, like a compass needle, receive an external torque that attempts to rotate it into alignment with the local magnetic field. This can be accounted for in the process model.
* **Kelly Factor**. The Kelly factor is a parameter that is used to quantify the degree to which a CSS's output differs from an ideal cosine response. More detail in the [CSS post](https://alexmcmaster.github.io/blog/2024/07/26/css.html). This can be accounted for in the CSS measurement model.
* **Sensor Bias**. An ideal sensor always outputs the true value. An non-ideal sensor with ideal noise (that is, white noise, which means zero mean and uncorrelated) has the true value as its mean output, so that if you average its outputs over time, the average will converge to the true value. The latter is what our simulation currently has (for CSS and for TAM), but neither is realistic. In the real world a sensor's mean output is always offset from the true value. This offset is known as bias. Bias may be relatively static in time, in which case it can be measured on the ground as part of calibration. Or, bias may drift over time, in which case it must be estimated using parameter/state estimation techniques. Either way, this bias is inherent and will degrade ADS accuracy unless modeled and accounted for effectively. This can be accounted for in the measurement models.

## Ways to Improve the ADS

The ADS that we have designed here is fairly bare bones. Here are some of the ways that it can be improved:

* **Error-State EKF (ES-EKF)**. There is a problem with using a traditional EKF for EP estimation: it has no conception of the unit norm constraint. We paper over this be constantly re-normalizing the attitude quaternion, but this is a hack that relies on the [small-angle approximation](https://en.wikipedia.org/wiki/Small-angle_approximation), and so is only effective to the extent that our ```dt``` and angular rates are small. A better solution is to use an ES-EKF. Unlike a traditional EKF, which directly estimates the state vector, an ES-EKF estimates the adjustment needed to bring our current best estimate of the state vector up-to-date. Because this "adjustment" is not subject to the unit norm constraint we do not need to constantly re-normalize, and so this source of error is eliminated.
* **More Sensors**. Our current ADS requires only a single TAM and 6 CSSs. This is pretty cool. However, it has some drawbacks. For one thing, the amount of noise generated by these sensors limits our steady-state pointing accuracy to somewhere in the realm of +/- 1 degree. This is too high for a lot of common applications. For another thing, it leads to issues with observability. There are regions in Earth orbit (near the poles) in which the magnetic field vector and the Sun vector are aligned, or nearly aligned, which means that the two types of sensor are actually giving us the same information (this is known as Geometric Dilution of Precision or [GDOP](https://en.wikipedia.org/wiki/Dilution_of_precision_(navigation)). Basically what this means is that our ADS's state covariance will balloon in these regions, leading to poor performance. We can address both of these problems by adding star trackers to our spacecraft. I'll do a whole post on star trackers in at some point, but the important thing to know is that they're very accurate, very precise, and very costly compared to CSS and TAM. Another sensor that we could add is an Inertial Measurement (IMU) with rate gyros. This would allow us to measure angular acceleration, which we could integrate to get a much better estimate of the angular rates.
* **Analytical Jacobians**. I noted in the Code section that our current ADS uses numerical differentiation to calculate the Jacobians of the process and measurement models at each time step. This is fine for development. However, these Jacobians can be solved by hand and hard-coded, speeding up the estimation process significantly (my guess would be a factor of 2-10). Now, this current ADS runs at ~10x real-time on my laptop, which is plenty fast, but you can expect it to be quite a bit slower on a typical flight computer. So, in order to maximize computational efficiency, it would be wise to switch to analytical Jacobians before using this system in practice.

# Conclusion

In this post we finally presented a functional attitude determination system (ADS). We started off with a review of some prerequisite knowledge, moved on to a walkthrough of the simulation and ADS code, analyzed its performance and talked about the ways in which the system can be improved. In future posts I want to explore some of these avenues of improvement and see if we can't eventually get to a full-featured, modern ADS.

# Links

[PDF link](https://core.ac.uk/download/pdf/32552678.pdf) - In this paper the authors describe their own CSS/TAM ADS implementation. I actually didn't use this as a reference, but you should recognize equations 6 and 7 as describing the same process model used in our implementation. This paper goes into a lot of detail about albedo modeling and compensation.

[PDF link](https://ntrs.nasa.gov/api/citations/20110007876/downloads/20110007876.pdf) - This NASA paper goes into more detail about the various sources of disturbance forces and torques (SRP, drag, etc.) that need to be considered when building a simulation environment.